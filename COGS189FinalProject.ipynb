{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## COGS 189, Winter 2021\n",
    "## Yleia Sanchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, my goal was to examine how well different classification methods were at classifying brain waves. I wanted to examine different classification methods because I was interested in learning how much classifications methods can vary when being used on the same dataset.\n",
    "\n",
    "Because this class focuses on brain-computer interfaces (BCI), I aimed at chosing a dataset that would help me understand how we use eeg data in a relatively straightforward way. \n",
    "The dataset I chose to uses measured participants brain activities while completing a number of tasks using EEG. On two ends of this spectrum, we have participants doing math versus participants relaxing.\n",
    "\n",
    "For this project, we are going to focus mainly on the classification of our 'relax' signals by comparing k-nearest neighbors (KNN), decision trees, extra trees, random forests, gadient boost, and support vector classification (SVC) from the sklearn library in order to find the most accurate classification method.\n",
    "\n",
    "dataset: https://www.kaggle.com/berkeley-biosense/synchronized-brainwave-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all code derived from:\n",
    "https://www.kaggle.com/elsehow/classifying-relaxation-versus-doing-math\n",
    "and \n",
    "https://www.kaggle.com/seaneuron/math-relax-prediction-with-different-classifiers\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"eeg-data.csv\")\n",
    "\n",
    "df.raw_values = df.raw_values.map(json.loads)\n",
    "df.eeg_power = df.eeg_power.map(json.loads)\n",
    "\n",
    "relax = df[df.label == 'relax']\n",
    "math = df[(df.label == 'math1') |\n",
    "          (df.label == 'math2') |\n",
    "          (df.label == 'math3') |\n",
    "          (df.label == 'math4') |\n",
    "          (df.label == 'math5') |\n",
    "          (df.label == 'math6') |\n",
    "          (df.label == 'math7') |\n",
    "          (df.label == 'math8') |\n",
    "          (df.label == 'math9') |\n",
    "          (df.label == 'math10') |\n",
    "          (df.label == 'math11') |\n",
    "          (df.label == 'math12') ]\n",
    "\n",
    "def vectorLabels(List1, List2):\n",
    "    x = List1 + List2\n",
    "    def Label(L):\n",
    "        return lambda x: L\n",
    "    y = list(map(Label(0), List1)) + list(map(Label(1), List2))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>251826.381818</td>\n",
       "      <td>448237.301788</td>\n",
       "      <td>792.0</td>\n",
       "      <td>16553.00</td>\n",
       "      <td>62783.5</td>\n",
       "      <td>263056.25</td>\n",
       "      <td>3240799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>61600.065775</td>\n",
       "      <td>107685.398107</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>13551.50</td>\n",
       "      <td>28350.0</td>\n",
       "      <td>62940.50</td>\n",
       "      <td>1416472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_alpha</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>26878.933155</td>\n",
       "      <td>42728.938431</td>\n",
       "      <td>266.0</td>\n",
       "      <td>5431.00</td>\n",
       "      <td>13161.0</td>\n",
       "      <td>30288.75</td>\n",
       "      <td>586468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_alpha</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>22633.841711</td>\n",
       "      <td>32244.913432</td>\n",
       "      <td>151.0</td>\n",
       "      <td>5665.75</td>\n",
       "      <td>12452.5</td>\n",
       "      <td>26788.25</td>\n",
       "      <td>694417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_beta</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>12294.291444</td>\n",
       "      <td>15694.896534</td>\n",
       "      <td>295.0</td>\n",
       "      <td>4451.00</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>14781.50</td>\n",
       "      <td>315512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_beta</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>11200.815508</td>\n",
       "      <td>12187.141656</td>\n",
       "      <td>205.0</td>\n",
       "      <td>4664.00</td>\n",
       "      <td>7695.5</td>\n",
       "      <td>12873.00</td>\n",
       "      <td>148264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_gamma</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>6681.974866</td>\n",
       "      <td>10671.456080</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2163.50</td>\n",
       "      <td>3839.0</td>\n",
       "      <td>7019.25</td>\n",
       "      <td>151891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid_gamma</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>4806.425134</td>\n",
       "      <td>6479.447878</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1664.00</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>5640.25</td>\n",
       "      <td>94695.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean            std     min       25%      50%  \\\n",
       "delta       1870.0  251826.381818  448237.301788   792.0  16553.00  62783.5   \n",
       "theta       1870.0   61600.065775  107685.398107  1159.0  13551.50  28350.0   \n",
       "low_alpha   1870.0   26878.933155   42728.938431   266.0   5431.00  13161.0   \n",
       "high_alpha  1870.0   22633.841711   32244.913432   151.0   5665.75  12452.5   \n",
       "low_beta    1870.0   12294.291444   15694.896534   295.0   4451.00   8020.0   \n",
       "high_beta   1870.0   11200.815508   12187.141656   205.0   4664.00   7695.5   \n",
       "low_gamma   1870.0    6681.974866   10671.456080    86.0   2163.50   3839.0   \n",
       "mid_gamma   1870.0    4806.425134    6479.447878    25.0   1664.00   3013.0   \n",
       "\n",
       "                  75%        max  \n",
       "delta       263056.25  3240799.0  \n",
       "theta        62940.50  1416472.0  \n",
       "low_alpha    30288.75   586468.0  \n",
       "high_alpha   26788.25   694417.0  \n",
       "low_beta     14781.50   315512.0  \n",
       "high_beta    12873.00   148264.0  \n",
       "low_gamma     7019.25   151891.0  \n",
       "mid_gamma     5640.25    94695.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organization of the training data\n",
    "import numpy as np\n",
    "\n",
    "trainData = pd.DataFrame(columns=[\"delta\", \"theta\", \"low_alpha\", \"high_alpha\", \\\n",
    "                                 \"low_beta\", \"high_beta\", \"low_gamma\", \"mid_gamma\"])\n",
    "for id in pd.unique(math[\"id\"]):\n",
    "    math1 = math[math['id']==id]\n",
    "    relax1 = relax[relax['id']==id]\n",
    "    x, y = vectorLabels(math1.eeg_power.tolist(), relax1.eeg_power.tolist())\n",
    "    x = np.matrix(x)\n",
    "    y = np.array(y)\n",
    "    data = pd.DataFrame(data = x,\n",
    "                        index = y,\n",
    "                        columns = [\"delta\", \"theta\", \"low_alpha\", \"high_alpha\", \\\n",
    "                                 \"low_beta\", \"high_beta\", \"low_gamma\", \"mid_gamma\"])\n",
    "    frames = [trainData, data]\n",
    "    trainData = pd.concat(frames)\n",
    "trainData.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d0c71cc18>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of training data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = trainData.corr()\n",
    "plt.figure()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(trainData)\n",
    "pca = PCA(n_components = 2)\n",
    "pca_data = pca.fit_transform(data)\n",
    "plot_data = trainData\n",
    "plot_data[\"relax\"] = trainData.index\n",
    "#plt.scatter(pca_data[:, 0], pca_data[:, 1],\\\n",
    "#        c = plot_data[\"relax\"].apply(lambda relax: 'purple' if relax else 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1252, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "       trainData, trainData.index, test_size = 0.33, random_state = 42)\n",
    "xTrain = xTrain.drop(\"relax\", axis = 1)\n",
    "xTest = xTest.drop(\"relax\", axis = 1)\n",
    "xTrain.shape\n",
    "\n",
    "xTrain = xTrain.reset_index(drop = True)\n",
    "xTest = xTest.reset_index(drop = True)\n",
    "xTrain = pd.DataFrame(scaler.fit_transform(xTrain))\n",
    "xTest = pd.DataFrame(scaler.fit_transform(xTest))\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree & Extra Trees Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dectree = DecisionTreeClassifier(max_depth  = None, min_samples_split = 2)\n",
    "\n",
    "extree = ExtraTreesClassifier(n_estimators = 10, max_depth = None, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=True, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(100, max_features=None, min_samples_split=3, min_samples_leaf=3,\\\n",
    "                                random_state=42, n_jobs=-1, oob_score=True)\n",
    "forest.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>0.135621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_alpha</th>\n",
       "      <td>0.133487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_alpha</th>\n",
       "      <td>0.130687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_beta</th>\n",
       "      <td>0.128326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid_gamma</th>\n",
       "      <td>0.122169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_beta</th>\n",
       "      <td>0.120610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta</th>\n",
       "      <td>0.116269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_gamma</th>\n",
       "      <td>0.112831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Importance\n",
       "delta         0.135621\n",
       "high_alpha    0.133487\n",
       "low_alpha     0.130687\n",
       "high_beta     0.128326\n",
       "mid_gamma     0.122169\n",
       "low_beta      0.120610\n",
       "theta         0.116269\n",
       "low_gamma     0.112831"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(forest.feature_importances_,\n",
    "                        index=trainData.columns[0:8], \n",
    "                        columns=['Importance']).sort_values(['Importance'], ascending = False)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grboost = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclf = SVC(random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Results\n",
    "These comparisons were made by using the cross validation scores of each classifier.\n",
    "This was done by using the cross_val_score function from the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.605910819255054\n",
      "DecisionTreeClassifier 0.597363031233999\n",
      "ExtraTreesClassifier 0.6427667636985808\n",
      "GradientBoostingClassifier 0.6224560288909181\n",
      "SVC 0.6208242259404243\n",
      "RandomForestClassifier 0.6803065655290521\n"
     ]
    }
   ],
   "source": [
    "clfs = [knn, dectree, extree, grboost, svclf, forest]\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits = 10)\n",
    "for clf in clfs:\n",
    "    print(type(clf).__name__, np.mean(cross_val_score(clf, xTrain, yTrain, cv=cv, scoring=\"roc_auc\", n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordered Results\n",
    "\n",
    "### From my notebook: \n",
    "\n",
    "1. RandomForestClassifier 0.6803065655290521\n",
    "\n",
    "2. ExtraTreesClassifier 0.6427667636985808\n",
    "\n",
    "3. GradientBoostingClassifier 0.6224560288909181\n",
    "\n",
    "4. SVC 0.6208242259404243\n",
    "\n",
    "5. KNeighborsClassifier 0.605910819255054\n",
    "\n",
    "6. DecisionTreeClassifier 0.597363031233999\n",
    "\n",
    "### From the original notebook:\n",
    "https://www.kaggle.com/seaneuron/math-relax-prediction-with-different-classifiers\n",
    "\n",
    "1. RandomForestClassifier 0.661025241407\n",
    "\n",
    "2. SVC 0.632912741541\n",
    "\n",
    "3. GradientBoostingClassifier 0.620093471543\n",
    "\n",
    "4. ExtraTreesClassifier 0.616721153718\n",
    "\n",
    "5. KNeighborsClassifier 0.610764010965\n",
    "\n",
    "6. DecisionTreeClassifier 0.578443420379\n",
    "\n",
    "It should be noted that I used the same input parameters (n_estimators, min_samples_split, etc.) from the original notebook for my classification functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these results with mine, we see that the decision tree classifier ranked the lowest and the random forest classifier ranked the highest in both notebooks. This makes sense that this would be the order of the results as a random forest is a collection of decision trees, and therefore is expected to produce greater accuracy. \n",
    "However, the original notebook produces a cross validation scores of ~0.578 for its decision tree classification while I got a score of ~0.591 for my decision tree classification. Meanwhile, the original notebook scored its random forest classifier with a ~0.661 cross validation score while I recieved a ~0.680 for my random forest classifier. Looking at the results, my classifiers seemed to have scored better in general but also contain less variability than the results found in the original notebook.\n",
    "Also, the SVC and extra tree classifiers seemed to have traded spots for # 2 and 4 in our notebooks. Besides this though, my results seem to be somewhat expected.\n",
    "\n",
    "Something that surprised me was that the KNN algorithm scored relatively low in both notebooks. I found this interesting because I feel like KNN is the main classification algorithm taught in most machine learning classes, yet it doesn't seem to be very efficient or accurate. I think that this project has really encouraged me to learn more about other classification methods such as decision trees and SVC. \n",
    "\n",
    "This project has taught me that working with EEG data can be tricky. You always want to make sure that the dataset you're using a valid dataset published by people familiar with EEG in order to prevent mistakes such as classifying time. Additionally, as you can probably tell, the general cross validation scores produced here are not ideal.\n",
    "When looking through other notebooks such as https://www.kaggle.com/elsehow/classifying-relaxation-versus-doing-math, the results never seemed to be exemplary. This particular notebook seemed to hugely overfit the data and managed to yield 100% accuracy for some predictions. I find these results hard to believe considering I just tested 6 different classification methods and came nowhere near 100% accuracy. Although, this is just a problem in general. \n",
    "\n",
    "Overall, this project has taught me a lot about working with EEG data and the contrast that different classification algorithms can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.5943767165485804\n",
      "ExtraTreesClassifier 0.6337138045518721\n",
      "GradientBoostingClassifier 0.6006550566473556\n"
     ]
    }
   ],
   "source": [
    "# Just for fun\n",
    "knn2 = KNeighborsClassifier(n_neighbors=7)\n",
    "extree2 = ExtraTreesClassifier(n_estimators=7, max_depth=None, min_samples_split=2)\n",
    "grboost2 = GradientBoostingClassifier(n_estimators=7, learning_rate=1.0, max_depth=1)\n",
    "clfs2 = [knn2, extree2, grboost2]\n",
    "cv = StratifiedKFold(n_splits=7)\n",
    "for clf in clfs2:\n",
    "    print(type(clf).__name__, np.mean(cross_val_score(clf, xTrain, yTrain, cv=cv, scoring=\"roc_auc\", n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would be interested in knowing why the extra trees classifier works better when n is decreased from 10 to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
